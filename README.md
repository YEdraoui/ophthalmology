# ğŸ¥ Ophthalmology AI - Clinical Decision Support System

A full-stack AI-powered web application for diabetic retinopathy detection and clinical report generation.

![Next.js](https://img.shields.io/badge/Next.js-14-black)
![TypeScript](https://img.shields.io/badge/TypeScript-5-blue)
![Python](https://img.shields.io/badge/Python-3.11-green)
![License](https://img.shields.io/badge/License-MIT-yellow)

## ğŸ“‹ Overview

This system combines state-of-the-art computer vision (ConvNeXt-Tiny) with vision-language models (Llama 3.2-Vision 11B) to provide:
- **Automated DR screening** across 5 severity levels
- **Multi-condition detection** for 13 retinal abnormalities
- **AI-generated clinical reports** with treatment recommendations
- **Real-time analysis** with comprehensive visualizations

### ğŸ“Š Performance Metrics
| Metric | Value |
|--------|-------|
| Overall AUROC | 83.5% |
| Diabetic Retinopathy AUROC | 98.7% |
| Training Dataset | 60,000+ fundus images |
| Conditions Detected | 13 retinal abnormalities |
| Severity Levels | 5 (No DR, Mild, Moderate, Severe, Proliferative) |

## ğŸ—ï¸ System Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 USER INTERFACE (Browser)                    â”‚
â”‚            Next.js 14 + TypeScript + Tailwind               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚ HTTP/REST API
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 BACKEND API (Flask)                         â”‚
â”‚            Python 3.11 + Flask + CORS                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              AI INFERENCE PIPELINE                          â”‚
â”‚                                                             â”‚
â”‚  1. Vision Model: ConvNeXt-Tiny (PyTorch)                   â”‚
â”‚     - Input: 224x224 fundus images                          â”‚
â”‚     - Output: 13 conditions + 5 severity levels             â”‚
â”‚     - Performance: 83.5% AUROC                              â”‚
â”‚                                                             â”‚
â”‚  2. VLM: Llama 3.2-Vision 11B (Ollama)                      â”‚
â”‚     - Input: Image + Vision model predictions               â”‚
â”‚     - Output: Clinical reports                              â”‚
â”‚     - RAG: Medical knowledge base integration               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Tech Stack

### Frontend
- **Framework:** Next.js 14 (App Router)
- **Language:** TypeScript 5
- **Styling:** Tailwind CSS 4
- **UI Components:** shadcn/ui + Radix UI
- **State Management:** Zustand (with persist)
- **Charts:** Recharts
- **Animations:** Framer Motion

### Backend
- **API Server:** Flask 3.0
- **Image Processing:** OpenCV, Pillow
- **Deep Learning:** PyTorch 2.1, torchvision
- **Vision Model:** ConvNeXt-Tiny (timm)
- **VLM:** Llama 3.2-Vision 11B (Ollama)

### AI/ML Models

**1. Vision Model (ConvNeXt-Tiny)**
- Architecture: ConvNeXt-Tiny with custom multi-task head
- Parameters: 38.4M
- Input: 224x224 RGB fundus images
- Tasks: Binary classification (13 conditions) + Multi-class (5 DR severity levels)

**2. Vision-Language Model (Llama 3.2-Vision 11B)**
- Purpose: Clinical report generation
- Input: Fundus image + vision model predictions
- Output: Structured clinical reports with RAG-enhanced recommendations

## ğŸ“ Project Structure
```
ophthalmology-ai-nextjs/
â”œâ”€â”€ app/                          # Next.js app directory
â”‚   â”œâ”€â”€ dashboard/                # Analysis dashboard page
â”‚   â”œâ”€â”€ history/                  # Analysis history page
â”‚   â”œâ”€â”€ layout.tsx                # Root layout
â”‚   â”œâ”€â”€ page.tsx                  # Home page
â”‚   â””â”€â”€ globals.css               # Global styles
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ analysis/                 # Analysis-related components
â”‚   â”‚   â”œâ”€â”€ SeverityGauge.tsx     # Animated severity display
â”‚   â”‚   â”œâ”€â”€ PredictionsTable.tsx  # Conditions table
â”‚   â”‚   â”œâ”€â”€ ImagePreview.tsx      # Image viewer with zoom
â”‚   â”‚   â”œâ”€â”€ ClinicalReport.tsx
â”‚   â”‚   â””â”€â”€ ExportButtons.tsx
â”‚   â”œâ”€â”€ layout/
â”‚   â”‚   â””â”€â”€ Navbar.tsx
â”‚   â””â”€â”€ ui/                       # shadcn/ui components
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ api.ts                    # API client for Flask backend
â”‚   â”œâ”€â”€ types.ts                  # TypeScript definitions
â”‚   â””â”€â”€ utils.ts
â”œâ”€â”€ stores/
â”‚   â””â”€â”€ analysisStore.ts          # Zustand state management
â”œâ”€â”€ python-backend/
â”‚   â”œâ”€â”€ app.py                    # Flask API server
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ uploads/
â””â”€â”€ public/
```

## âš¡ Installation & Setup

### Prerequisites
- Node.js 20+
- Python 3.11+
- CUDA-capable GPU (recommended)
- Ollama

### 1. Clone Repository
```bash
git clone https://github.com/YourUsername/ophthalmology-ai-nextjs.git
cd ophthalmology-ai-nextjs
```

### 2. Frontend Setup
```bash
npm install
```

### 3. Backend Setup
```bash
cd python-backend
pip install -r requirements.txt
```

### 4. Install Ollama and Pull Model
```bash
# Install Ollama from https://ollama.ai
ollama pull llama3.2-vision:11b
```

### 5. Configure Environment
```bash
# Create .env.local in root directory
NEXT_PUBLIC_API_URL=http://localhost:8000
```

## ğŸš€ Running the Application

You need **3 terminals**:

| Terminal | Command | Purpose |
|----------|---------|---------|
| 1 | `ollama serve` | VLM Server |
| 2 | `cd python-backend && python app.py` | Flask Backend |
| 3 | `npm run dev` | Next.js Frontend |

Access the application at: **http://localhost:3000**

## âœ¨ Features

### Core Features
- ğŸ”¬ **Real-time Image Analysis** - Upload fundus images for instant analysis
- ğŸ¯ **Multi-Condition Detection** - Detects 13 retinal abnormalities
- ğŸ“Š **Severity Classification** - 5-level DR severity grading
- ğŸ“ **AI-Generated Reports** - Clinical reports with treatment recommendations
- ğŸ“ˆ **Interactive Visualizations** - Animated gauges, charts, and tables
- ğŸ’¾ **Analysis History** - Persistent storage of past analyses
- ğŸ” **Advanced Search & Filter** - Search conditions, filter by severity
- ğŸ“¥ **Multiple Export Formats** - JSON, CSV, TXT downloads

### UI/UX Features
- Animated severity gauge with color coding
- Searchable and sortable predictions table
- Image preview with zoom and rotation
- Processing timeline with step-by-step progress
- Analytics dashboard with distribution charts
- Responsive design (mobile-friendly)
- Dark theme interface

## ğŸ“Š Model Performance

### Vision Model Metrics

| Condition | AUROC |
|-----------|-------|
| Overall | 83.5% |
| Diabetic Retinopathy | 98.7% |
| Microaneurysms | 87.3% |
| Hemorrhages | 89.1% |
| Hard Exudates | 85.6% |
| Soft Exudates | 82.4% |
| Neovascularization | 91.2% |

### Severity Classification

| Level | Precision | Recall | F1-Score |
|-------|-----------|--------|----------|
| No DR | 0.92 | 0.94 | 0.93 |
| Mild | 0.78 | 0.76 | 0.77 |
| Moderate | 0.81 | 0.79 | 0.80 |
| Severe | 0.85 | 0.83 | 0.84 |
| Proliferative | 0.89 | 0.91 | 0.90 |

## ğŸ”Œ API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/health` | GET | Health check |
| `/api/analyze` | POST | Analyze fundus image |

## ğŸ’» Usage Example
```typescript
import { apiClient } from '@/lib/api';

const result = await apiClient.analyzeImage(file, 'comprehensive');

console.log(result.severity);     // { level: 0, confidence: 0.99, name: "No DR" }
console.log(result.conditions);   // Array of 13 conditions
console.log(result.report);       // Clinical report text
```

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ‘¤ Author

**Yassir**
- Al Akhawayn University - Big Data Analytics
- GPA: 3.6 | Dean's List

## ğŸ™ Acknowledgments

- ConvNeXt architecture: Facebook AI Research
- Llama 3.2-Vision: Meta AI
- UI Components: shadcn/ui

---

**â­ If you find this project helpful, please give it a star!**
